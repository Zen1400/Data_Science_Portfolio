{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2785320c",
   "metadata": {},
   "source": [
    "## Before I get into $PCA$ I would like to brush up on some basic Linear Algebra concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c926501",
   "metadata": {},
   "source": [
    "### Dot Product\n",
    "\n",
    "* Dot Product is a directional multiplication, it describes the amount by which one vector goes in the direction of the another.\n",
    "\n",
    "\n",
    "$$\n",
    "\\vec{a}.\\vec{b} = |a|.|b|.cos(\\theta)\n",
    "$$\n",
    "***\n",
    " \n",
    "### Projection\n",
    "\n",
    "* You can think of the projection of $\\vec{a}$ on $\\vec{b}$ as the amount of information from $\\vec{a}$ that is contained in $\\vec{b}$, the projection is maximum when the two vectors are parallel and zero when they are orthogonal\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "***\n",
    "***\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"dot.png\" width=600 height=800 />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586d0da",
   "metadata": {},
   "source": [
    "## What is PCA ?\n",
    "\n",
    "Principal Component Analysis (PCA) is an unsupervised dimensionality reduction technique. The goal of PCA is to project the dataset onto a lower-dimensional space while preserving as much of the variance of the dataset as possible.\n",
    "\n",
    "PCA can be performed in 6 steps:\n",
    "\n",
    "1) Subtract the mean of each variable\n",
    "\n",
    "2) Calculate the Covariance Matrix\n",
    "\n",
    "3) Compute the Eigenvalues and Eigenvectors\n",
    "\n",
    "4) Sort Eigenvectors by corresponding Eigenvalues in descending order and select a subset from the rearranged Eigenvalue matrix\n",
    "\n",
    "5) Recast data along the principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec94c8",
   "metadata": {},
   "source": [
    "- $PCA$ combines features to produce new features that are uncolrrelated and orderd in terms of importance called $Principal$ \n",
    " $Components$\n",
    " \n",
    " How we can arrange data points on a line in a way that perserves as much information as possible ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c66d6f",
   "metadata": {},
   "source": [
    "- The first component of PCA is a unit vector that tries to maximize the information preserved meaning it tries to maximize the projection of the data points on it which is the the square of the dot product between data points and the unit vector.\n",
    "\n",
    "\n",
    "- To maximize the dot product of data points is an optimization problem :        $Max   \\sum (x_i^T.\\vec{u})^2$ Where $x_i$ is a data point and $\\vec{u}$ is the first component which is a unit vector\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
